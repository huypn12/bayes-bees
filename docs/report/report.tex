\documentclass[12pt]{article}

\usepackage[utf8]{inputenc}

% graphics
\usepackage{graphicx}
\usepackage[pdf]{graphviz}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{titling}
\usepackage{listings}
\usepackage{tikz}
\usetikzlibrary{automata,arrows,positioning,calc}



% citation
\usepackage{biblatex}
\addbibresource{report.bib}

% MACROS
\newcommand*{\QED}{\hfill\ensuremath{\square}}
\newcommand{\stirlingii}{\genfrac{\{}{\}}{0pt}{}}

\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]

\newtheorem{theorem}{Theorem}
\newtheorem{lemma}[theorem]{Lemma}

\newcommand{\subtitle}[1]{%
  \posttitle{%
    \par\end{center}
  \begin{center}\large#1\end{center}
  \vskip0.5em}%
}

\newcommand*{\oh}{\frac{1}{2}}
% title
\title{Bayesian parameter synthesis of Markov population models}
\subtitle{Master Project on Modeling of Complex, Self-organizing systems}
\author{Huy Phung\\University of Konstanz}
\date{\today}

\setlength{\headheight}{23pt}
\setlength{\parindent}{0.0in}
\setlength{\parskip}{0.0in}


\begin{document}
\maketitle
\pagebreak
\tableofcontents
\pagebreak

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
\begin{abstract}
  We study the collective behavior of a bee colony. Each bee in a colony
  possibly stings after observing a threat in the surrounding environment, and
  warn other bees by releasing a special substance, pheromone. By sensing the
  pheromone released in the environment, other bees in the colony may also
  sting. However, since stinging leads to the termination of an individual bee,
  it reduces the total defense capability as well. With parametric Discrete-time
  Markov chain as the model, we study how the actions of a single bee change
  with regarding to the colony size of and pheromone amount. This project
  propose and discuss Bayesian methods to estimate parameters of bees population
  models. It shows that the proposed methods is scalable and can deliver
  estimations of model parameters.
\end{abstract}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Preliminaries}
\subsection{Discrete time Markov Chain}
Assume that each bee in a colony decides its next action (to sting or not to
sting) based only on the current state of the environment, and the number of
bees who sting or not sting can be modeled as a Markov process. To reduce the
complexity of the model, we make another assumption that the states of the bees
colony are observed after uniform time duration, hence the model is of
discrete-time. 

\subsubsection{Definition}
\begin{definition}[Discrete Time Markov Chain]
  A Discrete Time Markov Chain (DTMC) is a tuple $(S,\mathbf{P}, S_{init}, AP,
  L)$ \cite{baier2008principles} 
  \begin{itemize}
  \item $S$ is a countable non-emty set of \textit{states}
  \item $\mathbf{P}:S\times S \rightarrow [0,1]$ is the \textit{transition probability}
    function, s.t $$\sum_{s'\in S}\mathbf{P}(s, s') = 1$$
  \item $S_{init}: S \rightarrow [0,1]$ is the \textit{initial distribution},
    s.t  $$\sum_{s'\in S}S_{init}(s') = 1$$
  \item $AP$ is a set of \textit{atomic propositions}
  \item $L: S \rightarrow 2^{AP}$ is the labelling function on states.
  \end{itemize}
\end{definition}

The transition probability function in DTMC is given as a stochastic matrix $\mathbf{P}$,
which satisfies the following properties
\begin{itemize}
\item $\mathbf{P}$ is a square matrix.
\item $\mathbf{P}_{i,j} \in [0,1]$.
\item $\sum_j\mathbf{P}_{i,j} = 1$
\end{itemize}

\begin{definition}[Strongly Connected Component]
  Let $\mathcal{M}=(S,\mathbf{P}, S_{init}, AP,L)$ a DTMC. A subset $S'\subset
  S$ is strongly connected if and only if for every pair $s_1,s_2\in S'$ there
  is a path between $s_1$ and $s_2$ which consists of only of state in $S'$. If
  there exist no $S''\subseteq S$, such that $S\subset S''$ and $S''$ is
  strongly connected, then $S'$ is a \textit{Strongly Connected Component}, or
  \textit{SCC} in short.
\end{definition}

\begin{definition}[Bottom Strongly Connected Component]
  Let $\mathcal{M}=(S,\mathbf{P}, S_{init}, AP,L)$ a DTMC and $S'\in S$ a
  Strongly Connected Component. $S'$ is also a \textit{Bottom Strongly Connected
    Component}, or \textit{BSCC} for short, if and only if there exist no state
  $s \in S\\S'$ that is reachable from any state in $S'$.
\end{definition}

\subsubsection{Parametric Discrete-time Markov Chain}
In order to generalize the stochastic matrix to encompass unknown information of
the system, we introduce \textit{parametric DTMC}. Let $\theta =
(\theta_1,\ldots,\theta_n) \in [0,1]^n$, we represent each element in matrix
$\mathbf{P}$ as a polynomial function of $\theta$. Let $\mathbf{Pol}_\theta$ be the
set of polynomials $P: [0,1]^n \rightarrow [0,1]$. We define
\textit{parametric Discrete-Time Markov Chain}, or \textit{pMC} for short, as
follow:

\begin{definition}[Parametric DTMC]
  A parametric Discrete Time Markov Chain (pMC for short) is a tuple $(S,\theta,
  \mathbf{P}_\theta, S_{init}, AP,
  L)$
  \begin{itemize}
  \item $S$ is a countable nonemty set of \textit{states}
  \item $\theta$ is the set of model parameters
  \item $\mathbf{P}:S \times S \rightarrow \mathbf{Pol}_\theta$ is the \textit{transition probability}
    function that map a transition relation between two states to a polynomial
    function of $\theta$
  \item $S_{init}: S \rightarrow [0,1]$ is the \textit{initial distribution},
    s.t  $$\sum_{s'\in S}S_{init}(s') = 1$$
  \item $AP$ is a set of \textit{atomic propositions}
  \item $L: S \rightarrow 2^{AP}$ is the labelling function on states.
  \end{itemize}
\end{definition}
A concrete assignment of $\theta$ on pMC induces a DTMC. In this project, we
concern about the problem of data-informed estimation of model parameter $\theta$.

\subsubsection{Markov population model}
In the scope of this project we concern \textit{population} of a bee colony.
\begin{definition}[Markov population model]
  
\end{definition}


\subsubsection{Steady-state distribution}



\subsection{Bayesian inference}
\subsubsection{Bayesian parameter estimation}
Let $D$ be observed data. In statistical inference, we assume that the observed
data has a probability distribution of unknown parameter $\theta$, i.e
$D \sim P(D|\theta)$. In frequentist approach, the estimation
of $\theta$ based on long-run property, that is, given a large enough sample
size, expected value of parameter estimation $\hat{\theta}$ is equal to
$\theta$. Therefore, frequentist approach requires to gather a large amount of
data to deliver a close estimation $\hat{\theta}$. In Bayesian approach, we
reuse the information \textit{beliefs} gained from observed data to enhance the
accuracy of the estimation of $\hat{\theta}$. The main advantage of Bayesian
approach over frequentist approach is that it require less data to obtain an
estimation $\hat{\theta}$.\\
The beliefs obtained from prior knowledge of model parameter $\theta$ is
represented by \textit{prior
  distribution} $\pi(\theta)$.\\
Also, we have probability distribution of observed data, given parameter
$\theta$, $P(D|\theta)$. This is also called \textit{likelihood function}.\\
With Bayesian formula, we have
\begin{align*}
  \pi(\theta | D) = \frac{P(D|\theta)\pi(\theta)}{\int_\theta P(D|\theta)\pi(\theta)d\theta}
\end{align*}
$\int_\theta P(D|\theta)\pi(\theta)d\theta$ is called \textit{marginal
  distribution}. $\pi(\theta | D)$ is called \textit{posterior distribution}.
Computing posterior distribution is the essential part of Bayesian inference,
since it gives us the estimation of parameter $\theta$.

\subsubsection{Posterior conjugation}
Conjugated posteriors are special cases of Bayesian inference, in which the
prior and posterior distribution belongs to the same family of distribution.
Conjugated posteriors give us significant benefits
\begin{enumerate}
\item Tractability: we have analytical form of posterior distribution.
\item Computationally effective: updating model parameter is of linear time to
  the dimension of parameter.
\end{enumerate}
We consider two conjugated posterior: Binomial-Beta and Dirichlet-Multinomial
\begin{lemma}[Binomial-Beta Conjugation]
  Binomial distribution is conjugated to beta distribution.
\end{lemma}
\begin{proof}
  The observed data $D=(x_1,\ldots,x_n)$ is sampled from $Binomial(k, \theta)$ function
  \begin{align*}
    P(D|\theta) = \prod_{i=1}^n{k\choose x_i}\theta^{x_i}(1-\theta)^{k-x_i}
  \end{align*}
  The parameter $\theta$ is of $Beta(\alpha, \beta)$ distribution
  \begin{align*}
    \pi(\theta) = \theta^{\alpha-1}(1-\theta)^{\beta -1}
  \end{align*}
  We obtained:
  \begin{align*}
    \pi(\theta|D) &\sim P(D|\theta)\pi(\theta) \\
                  &\sim \theta^{\sum_{i=1}^n x_i}(1-\theta)^{nk -\sum_{i=1}^n x_i} \theta^{\alpha -1} (1-\theta)^{\beta-1} \\
                  &= \theta^{\alpha - 1 + \sum_{i=1}^n x_i}(1-\theta)^{\beta - 1 + nk -\sum_{i=1}^n x_i}
  \end{align*}
  Thus, the posterior is $Beta(\alpha + \sum_{i=1}^n x_i, \beta + nk -\sum_{i=1}^n x_i)$
\end{proof}
Generalize this conjugation, we also have Multinomial-Dirichlet conjugation.
\begin{lemma}[Multinomial-Dirichlet Conjugation]
  Multinomial distribution is conjugated to Dirichlet distribution.
\end{lemma}
\begin{proof}
  The observed data $D=(x_1,\ldots,x_n)$ is sampled from $Multinomial(n; \theta_1,\ldots,\theta_n)$ function
  \begin{align*}
    P(x_1,\ldots,x_n | N, \theta_0,\ldots,\theta_n) &= \frac{n!}{x_1!\ldots x_n!} \prod_{i=1}^n\theta_i^{x_i}
  \end{align*}
  The parameter $(\theta_1,\ldots,\theta_n)$ is
  $Dirichlet(\alpha_1,\ldots,\alpha_n)$
  \begin{align*}
    \pi(\theta_1,\ldots,\theta_n) = \frac{1}{\mathbf{B}(\alpha_1,\ldots,\alpha_n)}\prod_{i=1}^n\theta_i^{\alpha_i - 1}
  \end{align*}
  We obtain
  \begin{align*}
    \pi(\theta_1,\ldots,\theta_n|D) &\sim P(D|\theta)\pi(\theta) \\
                                    &\sim \prod_{i=1}^n\theta_i^{x_i} \prod_{i=1}^n\theta_i^{\alpha_i - 1} \\
                                    &\sim \prod_{i=1}^n\theta_i^{\alpha_i - 1 + \sum_{i=1}^n x_i}
  \end{align*}
  Thus, the posterior is $Dirichlet(\alpha_1 +  x_1,\ldots,\alpha_n
  +  x_n)$
\end{proof}
More detailed description in these cases can be found in \cite{tu2014dirichlet}
and \cite{baron2019probability}. We summarize the necessary results in the following table:
\begin{table}[H]
\begin{tabular}{lllll}
\cline{1-3}
\multicolumn{1}{|l|}{Likelihood} & \multicolumn{1}{l|}{Prior} & \multicolumn{1}{l|}{Posterior parameters} &  &  \\ \cline{1-3}
  \multicolumn{1}{|l|}{$Binomial(k, \theta)$}  & \multicolumn{1}{l|}{$Beta(\alpha, \beta)$}  & \multicolumn{1}{l|}{$\alpha' = \alpha + \sum_{i=1}^n x_i, \beta' = \beta + nk -\sum_{i=1}^n x_i$}  &  &  \\ \cline{1-3}
  \multicolumn{1}{|l|}{$Multinomial(n; \theta_1,\ldots,\theta_n)$}  & \multicolumn{1}{l|}{$Dirichlet(\alpha_1,\ldots,\alpha_n)$}  & \multicolumn{1}{l|}{$\alpha_i' =\alpha_i + x_i, 1 \leq i \leq n$}  &  &  \\ \cline{1-3}
                        &                        &                        &  & 
\end{tabular}
\end{table}

\subsubsection{Metropolis-Hastings algorithm}
In case the posterior distribution has no analytical form or its analytical form
is difficult to sample from directly, we use \textit{Metropolis-Hastings}
algorithm (\textit{MH} in short).\\
Metropolis-Hastings algorithm is a \textit{Monte Carlo Markov Chain} algorithm.
In its essential, Metropolis-Hastings algorithm draws 
Using the MH algorithm, we can estimate the parameter by posterior mean, without
knowing the analytical form of posterior distribution itself.

\begin{algorithm}[H]
  \caption{Metropolis-Hastings Algorithm, $D$ is the observation data, $\theta$ is parameter}\label{mhalg}
  \begin{algorithmic}[1]
    \Procedure{Metropolis-Hastings}{$D$, maxIteration}
    \State Select a proposal distribution $\pi(\theta)$
    \State Initialize $\theta$
    \While{maxIteration not reached}
    \State $L \leftarrow P(D|\theta)$
    \State Draw $\theta' $ from the proposal distribution (transition kernel).
    \State $L' \leftarrow P(D|\theta')$
    \If{ $\ln(L') - \ln(L) > 0$ }
    \State  $\theta = \theta'$ (accept $\theta'$)
    \Else
    \State with probability $\epsilon$ accept $\theta'$ (avoiding local maxima)
    \EndIf
    \EndWhile
    \EndProcedure
  \end{algorithmic}
\end{algorithm}
The likelihood function can be implemented as log-likelihood to avoid underflow
error. Proposal distribution defines how do we proceed to the next parameter
value on the parameter space; it can be of any distribution family.

\subsubsection{Selection of prior distribution}
In this
project,
since parameters are in $[0,1]$, we select Beta distribution as proposal.\\
There are different methods to select the initial value of parameter $P$. In
this project, we initialize $P$ randomly. There are two advantages of using
Markov Chain Monte Carlo in Bayesian inference:
\begin{enumerate}
\item Parameter transition only needs the computation of likelihood function.
  Therefore, Monte Carlo Markov Chain can be used in general Bayesian inference,
  in which we are not guaranteed to have an analytical form of posterior.
\item Specifically in Metropolis-Hastings algorithm, marginal distribution is
  cancelled out, thus make MH a computationally efficient algorithm.
\end{enumerate}
However, MH algorithm also has a drawback; its convergence becomes slower as the
dimension of parameter $\theta$ increases.

\subsubsection{Bayesian Parameter Estimation}
With posterior distribution $\pi(\theta|D)$ we estimate the parameter
$\hat{\theta}$ using Bayesian posterior mean:
\begin{align*}
  \hat{\theta} = \mathbf{E}[\theta] = \int_\theta \theta \pi(\theta|D) d\theta
\end{align*}
In case we have samples from posterior distribution, for example when we use MH
algorithm, the discrete form of posterior mean is used:
\begin{align*}
  \hat{\theta} = \mathbf{E}[\theta] = \sum_\theta \theta \pi(\theta|D)
\end{align*}
\begin{definition}[Bayesian Credible Set]
  Set C is a $(1 − \alpha )100\%$ credible set for the parameter $\theta$ if the posterior
  probability for $\theta$ to belong to C equals $(1 − \alpha)$.
  \begin{align*}
    P(\theta \in C | D) = \int_C \pi(\theta|D) d\theta = 1 - \alpha
  \end{align*}
\end{definition}
In this project, we use $0.95$ credible set, i.e $\alpha=0.05$
\begin{definition}[Highest Posterior Density credible set]
  Highest Posterior Density $(1-\alpha)100\%$ credible set (HDP for short) is the
  interval with minimum length over all Bayesian $(1-\alpha)100\%$ Credible Set.
\end{definition}

In this project, the HPD is calculated using PyMC3 library
\cite{salvatier2016pymc3}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
\section{Related works}
Markov chain and

Bayesian inference

Bees modeling

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
\section{Modeling of bees colony}
\subsection{Biological description}
We consider the collective action of a bee colony. Each bee in a colony could
possibly sting after observing a threat in the surrounding environment, and warn
other bees by releasing pheromone. By sensing the pheromone released in the
environment, other bees in the colony may also sting. Since stinging leads to
the termination of an individual bee, it reduces the total defense capability as
well. We studies how the actions of a bee changes with regarding to its
surrounding the environment. There are 3 assumptions on the system:
\begin{enumerate}
\item Each bee release an unit amount of pheromone immediately after stinging.
\item A bee dies after stinging and releasing pheromone. In the other words, no
  bee can sting more than once.
\item Stinging behaviour only depends on the concentration of pheromone in the
  environment.
\end{enumerate}
Under these assumption, a bee colony can be viewed as a set of agents (bees)
interact with each other in a closed environment with the appearance of a factor
\textit{pheromone}. Each agent in the colony observe the following two factors
of the environment: (1) amount of pheromone and (2) number of other agents.
Afterward, the agent has probability to commit an action, namely \textit{sting}.
The agent is eliminated from environment after stinging.

\subsection{Markov population models for bee colony}
Assume that we have a colony of $n$ bees initially. As aforementioned, an individual bee
is terminated after it stings. Thus, at the end of experiment, the number of
bees is $n'\in\{0,1,\ldots,n\}$. We model the bee colony with a DTMC
$\mathcal{M}=(S,\mathbf{P}, S_{init}, AP,L)$, such that
\begin{itemize}
\item $|S_{init}|=1$
\item There exists $n+1$ BSCCs $B_0,\ldots,B_n\in S$. These BSCCs encode the
  population at the end of the experiment.
\end{itemize}

In a bee colony, we can also ob
\begin{itemize}
\item Let $P(B_i)$ be the probability of the
\end{itemize}

Semantics of Markov population models for bees colony are developed by
\cite{hajnal2019data}. In this report we summarize three models of bees population
\begin{enumerate}
\item Synchronous model
\item Asynchronous model
\item Semi-synchronous model
\end{enumerate}
In the scope of this project we do not analyze the semantics of each model.
Instead, the inference methods presented only uses the polynomial function of
the models' steady-state distribution. 

\subsubsection*{Asynchronous model}
In asynchronous experiment we assume that there is almost improbable for two
bees to sting simultaneously, and any bees release pheromone immediately after
its death. By that observation we can assume that each bee
sting at different level of pheromone.\\
\begin{figure}[H]
  \centering 
  \begin{tikzpicture}[->, >=stealth', auto, semithick, node distance=3cm]
    \tikzstyle{every state}=[fill=white,draw=black,thick,text=black,scale=1]
    \node[state]    (A)                     {init};
    \node[state]    (B)[above right of=A]   {$\oh$};
    \node[state]    (C)[below right of=A]   {$1$};
    \node[state]    (D)[above right of=B]   {$\oh \oh$};
    \node[state]    (E)[below of=D]         {$\oh 1$};
    \node[state]    (F)[below of=E]         {$1 1$};
    \node[state]    (G)[above right of=D]   {$\oh \oh \oh$};
    \node[state]    (H)[below of=G]         {$\oh \oh 1$};
    \node[state]    (I)[below of=H]         {$\oh 1 1$};
    \node[state]    (J)[below of=I]         {$1 1 1$};
    \node[state]    (K)[right of=H]         {$0 \oh 1$};
    \node[state]    (L)[right of=I]         {$0 1 1$};
    \node[state]    (M)[right of=K]         {$0 0 1$};
    \path
    (A) edge node{$1-p$} (B)
    edge node{$p$} (C)
    (B) edge node{$1-p$} (D)
    edge node{$p$} (E)
    (C) edge node{$1-p$} (E)
    edge node{$p$} (F)
    (D) edge node{$1-p$} (G)
    edge node{$p$} (H)
    (E) edge node{$1-p$} (H)
    edge node{$p$} (I)
    (F) edge node{$1-p$} (I)
    edge node{$p$} (J)
    (H) edge node{$1-q$} (K)
    edge node{$q$} (I)
    (I) edge node{$1-q$} (L)
    edge node{$p$} (J)
    (K) edge node{$1-q$} (M)
    edge node{$p$} (L);
  \end{tikzpicture}
  \caption{Example asynchronous model of 3 bees, 2 parameters}
\end{figure}


\subsubsection*{Synchronous model}
In \textit{fully synchronous} experiment we assume that the number of stinging
bees is only counted after a fixed amount of time, so that without loss of
generality we can assume the pheromone diffuse almost immediately among the bee
colony, and each bee decide to sting or not to sting immediately after sensing
the pheromone concentration.\\

\begin{figure}[H]
  \centering 
\begin{tikzpicture}[->, >=stealth', auto, semithick, node distance=3cm]
\tikzstyle{every state}=[fill=white,draw=black,thick,text=black,scale=1]
\node[state]    (A)                     {init};
\node[state]    (B)[right of=A]         {$\oh \oh 1 $};
\node[state]    (C)[above of=B]         {$\oh \oh \oh$};
\node[state]    (D)[below of=B]         {$\oh 1 1$};
\node[state]    (E)[below of=D]         {$1 1 1$};
\node[state]    (F)[right of=B]         {$0 0 1$};
\node[state]    (G)[right of=D]         {$0 1 1$};
\path
(A) edge    node{$(1-p)^3$}        (C)
    edge    node{$3p(1-p)^2$}     (B)
    edge    node{$3p(1-p)^2$}      (D)
    edge    node{$p^3$}            (E)
(B) edge    node{$(1-q)^2$}        (F)
    edge    node{$(2q(1-q)$}       (G)
    edge[bend left,below]    node{$q^2$}            (E)
(D) edge    node{$(1-q)$}          (G)
    edge    node{$q$}              (E); 
  \end{tikzpicture}
  \caption{Example synchronous model of 3 bees, 2 parameters.}
\end{figure}



\subsubsection*{Semi-synchronous model}
In \textit{Semisynchronous model}, we assume that the behaviour is initally
synchronous. That means, at the initial states we do synchronous update. From
all succeeding states from initial states, the updates are of asynchronous semantics.
\begin{figure}[H]
  \centering 
  \begin{tikzpicture}[->, >=stealth', auto, semithick, node distance=3cm]
    \tikzstyle{every state}=[fill=white,draw=black,thick,text=black,scale=1]
    \node[state]    (A)                     {init};
    \node[state]    (B)[right of=A]         {$\oh \oh 1 $};
    \node[state]    (C)[above of=B]         {$\oh \oh \oh$};
    \node[state]    (D)[below of=B]         {$\oh 1 1$};
    \node[state]    (E)[below of=D]         {$1 1 1$};
    \node[state]    (F)[right of=B]         {$0 \oh 1$};
    \node[state]    (G)[right of=D]         {$0 1 1$};
    \node[state]    (H)[right of=F]         {$0 1 1$};
    \path
(A) edge    node{$(1-p)^3$}        (B)
    edge    node{$(3p(1-p)^2$}     (C)
    edge    node{$3p(1-p)^2$}      (D)
    edge    node{$p^3$}            (E)
(B) edge    node{$1-q$}            (F)
    edge    node{$q$}              (D)
(D) edge    node{$(1-q)$}          (G)
    edge    node{$q$}              (E)
(F) edge    node{$q$}              (G)
    edge    node{$1 - q$}          (H);
  \end{tikzpicture}
  \caption{Example semisynchronous model of 3 bees, 2 parameters}
\end{figure}

For a population of $n$ bees, all three types of models share two properties:
\begin{enumerate}
\item Has exactly one initial state, $|S_{init}| = 1$. This assumption is
  obvious, since at the beginning of the experiment, all bees are alive.
\item Has $n+1$ tSCCs $(tSCC_0,\ldots,tSCC_n)$. This is because the number of
  dead bees cannot exceed the population size. It also follows that
  \begin{align*}
    \sum_{i=0}^n P(FG\quad tSCC_i) = 1
  \end{align*}
\end{enumerate}


\subsubsection{Linear model}
asdf

\subsubsection{Steady-state distribution}
In the bees population models, the steady state distribution is defined as
follow:
\begin{definition}[Steady-state distribution]
  
\end{definition}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Bayesian parameter synthesis of Markov population model}
\subsection{Inference of steady state distribution}
Let
Using the Multinomial-Dirichlet conjugation, we can infer  the steady state
distribution as we observe new experiment data $D=(a_0,\ldots,a_n)$, with $a_i$
is the number of experiment in which the population in steady-state is $i$ 
\begin{algorithm}[H]
  \caption{Estimation of steady-state distribution given a sample $S$}\label{exp_a}
  \begin{algorithmic}[1]
    \Procedure{Estimate $p_i = P(tSCC_i)$}{$S$}
    \State Initialize $\alpha_0=\alpha_1=\ldots=\alpha_n=1$
    \State Initialize $p_0=p_1=\ldots=p_n=0$
    \State Update $\alpha_i = \alpha_i + a_i, 1 \leq i \leq n$
    \State Update $p_i = \alpha_i / \sum_{i=1}^n \alpha_i, 1 \leq i \leq n$
    \EndProcedure
  \end{algorithmic}
\end{algorithm}

As later shown in the implementation with synthetic data, the Bayesian
estimation of steady-state distribution converges quickly to the true parameter
used for data synthesis. This method does not directly estimate the pMC
model parameters. However, it can support the parameter estimation presented
\cite{hajnal2019data} to estimate the model parameters with narrower credible
set.


\subsection{Evaluation of steady-state distribution}




\subsection{Inference of model parameters with rational functions}
We can also use Bayesian inference to estimate pMC model parameters directly.
Given a pMC $\mathcal{M}$ with $\theta=(\theta_1,\ldots,\theta_k)$ as its model
parameters. Since $\theta_i \in [0,1]$, we can assume that $\theta_i$ are of
$Beta(\alpha, \beta)$ distribution. Note that $\alpha, \beta$ are
hyperparameters and must be selected manually. Also note that
$\theta_1,\ldots,\theta_k$ are not simplex, thus it is not possible to use
Dirichlet prior. \\
In this method, since there is no possible use of posterior conjugation, thus
the hyperparameters estimation is hard and not in the scope of this project. Let
$f_i = P (FG\quad tSCC_i)$ are polynomial functions of steady-state
distribution, we denote $\epsilon_i = f_i(\theta)$ as evaluations of the
polynomial function with a concrete assignment of $\theta$. The steady-state
distribution has then $Multinomial(N, \epsilon = (\epsilon_0,\ldots,\epsilon_n))$ with $N$
is the sample size of experiment data $D$. The posterior distribution has the
following form:
\begin{align*}
  \pi(\theta|D) \sim Multinomial(N, (\epsilon_0,\ldots,\epsilon_n))\pi(\theta_1)\ldots\pi(\theta_k)
\end{align*}
As the posterior $\pi(\theta|D)$ has no analytical form, we use
Metropolis-Hastings to sample from it.
\begin{algorithm}[H]
  \caption{Estimation of model parameters given a sample $D$}\label{exp_b}
  \begin{algorithmic}[1]
    \Procedure{Estimate $\theta$}{$S$}
    \State Select hyperparameter $\alpha, \beta$
    \State Select $Beta(\alpha, \beta)$ as proposal distribution (transition
    kernel) for $\theta_i, 1\leq i \leq n$
    \State Initialize $\theta$
    \While{maxIteration not reached}
    \State Evaluate $\epsilon = (f_0(\theta),\ldots,f_n(\theta))$
    \State $L \leftarrow Multinomial(D|\epsilon)$
    \State Draw $\theta'$ from the proposal distribution.
    \State Evaluate $\epsilon' = (f_0(\theta),\ldots,f_n(\theta))$
    \State $L' \leftarrow P(D|\epsilon')$
    \If{ $\ln(L') - \ln(L) > 0$ }
    \State  $\theta = \theta'$ (accept $\theta'$)
    \Else
    \State with probability $\epsilon$ accept $\theta'$ (avoiding local maxima)
    \EndIf
    \EndWhile
    \EndProcedure
  \end{algorithmic}
\end{algorithm}

\subsection{Inference of model parameter with Metropolis-Hastings algorithm}
We can also use Bayesian inference to estimate pMC model parameters directly.
Given a pMC $\mathcal{M}$ with $\theta=(\theta_1,\ldots,\theta_k)$ as its model
parameters. Since $\theta_i \in [0,1]$, we can assume that $\theta_i$ are of
$Beta(\alpha, \beta)$ distribution. Note that $\alpha, \beta$ are
hyperparameters and must be selected manually. Also note that
$\theta_1,\ldots,\theta_k$ are not simplex, thus it is not possible to use
Dirichlet prior. \\
In this method, since there is no possible use of posterior conjugation, thus
the hyperparameters estimation is hard and not in the scope of this project. Let
$f_i = P (FG\quad tSCC_i)$ are polynomial functions of steady-state
distribution, we denote $\epsilon_i = f_i(\theta)$ as evaluations of the
polynomial function with a concrete assignment of $\theta$. The steady-state
distribution has then $Multinomial(N, \epsilon = (\epsilon_0,\ldots,\epsilon_n))$ with $N$
is the sample size of experiment data $D$. The posterior distribution has the
following form:
\begin{align*}
  \pi(\theta|D) \sim Multinomial(N, (\epsilon_0,\ldots,\epsilon_n))\pi(\theta_1)\ldots\pi(\theta_k)
\end{align*}
As the posterior $\pi(\theta|D)$ has no analytical form, we use
Metropolis-Hastings to sample from it.
\begin{algorithm}[H]
  \caption{Estimation of model parameters given a sample $D$}\label{exp_b}
  \begin{algorithmic}[1]
    \Procedure{Estimate $\theta$}{$S$}
    \State Select hyperparameter $\alpha, \beta$
    \State Select $Beta(\alpha, \beta)$ as proposal distribution (transition
    kernel) for $\theta_i, 1\leq i \leq n$
    \State Initialize $\theta$
    \While{maxIteration not reached}
    \State Evaluate $\epsilon = (f_0(\theta),\ldots,f_n(\theta))$
    \State $L \leftarrow Multinomial(D|\epsilon)$
    \State Draw $\theta'$ from the proposal distribution.
    \State Evaluate $\epsilon' = (f_0(\theta),\ldots,f_n(\theta))$
    \State $L' \leftarrow P(D|\epsilon')$
    \If{ $\ln(L') - \ln(L) > 0$ }
    \State  $\theta = \theta'$ (accept $\theta'$)
    \Else
    \State with probability $\epsilon$ accept $\theta'$ (avoiding local maxima)
    \EndIf
    \EndWhile
    \EndProcedure
  \end{algorithmic}

%% TODO: result description
 
\end{algorithm}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Implementation}
The Bayesian inference methods are implemented in Python 3 and tested in the
followin system configuration:
\begin{itemize}
\item Intel Core i5-8265U @ 1.60GHz
\item 16GB RAM
\item OpenSUSE Tumbleweed 20200427
\item Anaconda 3 2019.10 for linux x86\_64
\end{itemize}
The following experiment on Bayesian inference use synthetic data from
semi-synchronous models of 2, 5 and 10 bees (in order to compare the performance
with related work in \cite{hajnal2019data}).

\subsection{PRISM model and result processing}
asdf



\subsection{Metropolis-Hastings algorithm implementation}
A script \texttt{parse\_prism.py} is include in folder \texttt{models} to parse
PRISM polynomial string to a Python class template. This is to avoid calling
expensive function \texttt{eval()} on runtime. Source code structure:
\begin{itemize}
\item \texttt{docs} folder contains final report
\item \texttt{impl} folder contains python implementation and PRISM results
  parsed to Python classes
\item \texttt{examples} folder contains jupyter notebook examples.
\end{itemize}


\subsection{Class design}
\begin{figure}[H]
  \centering
  \includegraphics[width=0.6\textwidth,keepaspectratio]{figures/class_diagram.png}
  \caption{Class diagram of the project}
\end{figure}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Benchmark}
\subsection{Data synthesis}
The data synthesis for $n$ bees population is conducted as follow:
\begin{itemize}
\item Select a pMC model $\mathcal{M}$ to model the population of . Let
  $\bar{p}=p_1,\ldots,p_n$ is the model parameter vector.
\item Assign a concrete value for $\bar{p}$, called $\bar{p}_{true}$
\item From $\mathcal{M}$, deliver the rational functions of $f_i(\bar{p}) =
  P(FG\quad tSCC_i)$, $0 \leq i \leq n$. (using PRISM Model Checker \cite{KNP11})
\item Evaluate concrete value $\theta_i = f_i(\bar{p}_{true})$
\item Draw sample $S$ from multinomial distribution $Multinomial(N,
  \theta=(\theta_0,\ldots,theta_n))$
\item $S$ is the synthetic result for the experiment 3.1
\end{itemize}

\begin{figure}[H]
  \centering
  \includegraphics[width=0.6\textwidth,keepaspectratio]{figures/data_synthesis.png}
  \caption{Steady state data synthesis, semi-synchronous model of 5 bees
    population, model parameters $(0.3, 0.25, 0.35, 0.45, 0.5)$}
\end{figure}

\subsection{Evaluation measures}
In order to evaluate the accuracy of parameter point inference, we have to
select a distance measure from estimated parameter to true parameter. In this
project we use two measures:
\begin{definition}[RMSE]
  Let $\theta = (\theta_1,\ldots,\theta_n)$ and $\hat{\theta} =
  (\hat{\theta_1},\ldots,\hat{\theta_n})$ be vectors of $n$ real numbers, the
  Root Mean Square Error between $p$ and $\hat{p}$ is defined as follow:
  \begin{align*}
    RMSE(\theta, \hat{\theta}) = \sqrt{\frac{\sum_{i=1}^n{(\theta_i - \hat{\theta_i})}}{n}}
  \end{align*}
\end{definition}

\subsection{Comparison of DTMC sampling and rational functions evaluation}
Given a bee population model $\mathcal{M}$, we have two methods to obtain
steady-state distribution:

\subsection{Inference of steady state distribution}
This experiment is conducted on semisynchronous model of 5 bees. The polynomial
functions of steady-state distribution is generated by PRISM and parsed into
Python 3 source code
(\texttt{semisync\_5bees.py}). The source code for this
experiment is on Jupyter Notebook file \texttt{visualization.ipynb}
\begin{figure}[H]
  \centering
  \includegraphics[width=0.6\textwidth,keepaspectratio]{figures/point_estimation.png}
  \caption{Bayesian estimation of steady state distribution. Blue cross is true
    steady state evaluation.}
\end{figure}
In order to compare with the work by \cite{hajnal2019data}, we also visualize
the interval calculated by the following formula:
\begin{align*}
  \theta_i \pm (z_{\alpha / 2}\sqrt{\frac{\theta_i(1-\theta_i)}{N}})
\end{align*}
where $N$ is the sample size. Experiment configurations:
\begin{itemize}
\item true model parameter: $[0.3, 0.25, 0.35, 0.45, 0.5]$
\item tSCC distribution evaluation: $[0.1680, 0.1139, 0.2089, 0.2371, 0.1940, 0.0778]$ 
\end{itemize}

\begin{figure}[H]
  \centering
  \includegraphics[width=0.6\textwidth,keepaspectratio]{figures/interval_estimation.png}
  \caption{Comparision of Bayesian Highest Posterior Density 95\% (red bar) and interval
    estimated using method in \cite{hajnal2019data} (green bar). Red cross is
    true steady state evaluation.}
\end{figure}


\subsection{Inference of model parameters with rational functions}
This experiment is conducted in 2, 5, and 10 bees population models of 2, 5, and 10
parameters respectively. All models are semi-synchronous.\\

\subsection{Inference of model parameters with DTMC sampling}




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
\section{Conclusion}
The goal of this project is to experiment Bayesian approach on parameter
inference of Markov population models. The results shows that Bayesian inference
is efficient to deliver an estimation of model parameters. Furthermore, the
implementation is more efficient than the work in \cite{hajnal2019data} as it
can work with higher number of parameters and requires less computational
resources.\\
However, there are still problems
\begin{enumerate}
\item MH algorithm converges slower as the number of parameter increases, thus
  requires longer chain of sampling the parameter space, which may increase the
  computational cost dramatically.
\item PRISM is still necessary to deliver polynomial functions, thus introduce
  an overhead, that PRISM itself is resource-hungry.
\item In this project, there is no Bayesian inference, which is designed to deal
  with the case when the polynomial functions are hard to synthesize, or
  impossible to synthesize.
\end{enumerate}
However, we believe that the method can be developed further to overcome these limitations.


\printbibliography

\end{document}


